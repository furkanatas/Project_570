{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlt = pd.read_csv(r\"C:\\Users\\Mustafa Kaan\\Desktop\\dengue_labels_train.csv\")\n",
    "dft = pd.read_csv(r\"C:\\Users\\Mustafa Kaan\\Desktop\\dengue_features_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     city  year  weekofyear  total_cases week_start_date   ndvi_ne   ndvi_nw  \\\n",
      "818    sj  2006           3           19      2006-01-22 -0.194233 -0.111740   \n",
      "172    sj  1993          33           23      1993-08-20  0.096900  0.049667   \n",
      "401    sj  1998           3           49      1998-01-15 -0.016150 -0.008225   \n",
      "924    sj  2008           6            2      2008-02-05 -0.111700 -0.003200   \n",
      "1450   iq  2010          20            6      2010-05-21  0.263071  0.272500   \n",
      "...   ...   ...         ...          ...             ...       ...       ...   \n",
      "1169   iq  2004          52            7      2004-12-23  0.364862  0.326600   \n",
      "849    sj  2006          34           18      2006-08-27  0.064050  0.003450   \n",
      "602    sj  2001          48           47      2001-11-26  0.215150  0.226150   \n",
      "676    sj  2003          18            5      2003-04-30  0.068100  0.035500   \n",
      "97     sj  1992          11           40      1992-03-11  0.086850  0.090150   \n",
      "\n",
      "       ndvi_se   ndvi_sw  precipitation_amt_mm  ...  \\\n",
      "818   0.101514  0.101114                 74.41  ...   \n",
      "172   0.197071  0.163286                106.83  ...   \n",
      "401   0.204714  0.198571                106.97  ...   \n",
      "924   0.232843  0.271171                  0.00  ...   \n",
      "1450  0.258271  0.244500                  1.15  ...   \n",
      "...        ...       ...                   ...  ...   \n",
      "1169  0.403112  0.316200                109.83  ...   \n",
      "849   0.177300  0.178983                 70.61  ...   \n",
      "602   0.220629  0.198700                  9.43  ...   \n",
      "676   0.251271  0.212071                 26.56  ...   \n",
      "97    0.128000  0.155100                 23.22  ...   \n",
      "\n",
      "      reanalysis_precip_amt_kg_per_m2  reanalysis_relative_humidity_percent  \\\n",
      "818                             41.50                             78.720000   \n",
      "172                             62.70                             83.075714   \n",
      "401                             53.20                             84.694286   \n",
      "924                             19.70                             70.642857   \n",
      "1450                             8.80                             78.998571   \n",
      "...                               ...                                   ...   \n",
      "1169                            29.79                             93.252857   \n",
      "849                             39.50                             79.814286   \n",
      "602                              7.81                             74.344286   \n",
      "676                             15.20                             80.071429   \n",
      "97                              12.60                             78.057143   \n",
      "\n",
      "      reanalysis_sat_precip_amt_mm  reanalysis_specific_humidity_g_per_kg  \\\n",
      "818                          74.41                              15.794286   \n",
      "172                         106.83                              17.952857   \n",
      "401                         106.97                              16.208571   \n",
      "924                           0.00                              13.225714   \n",
      "1450                          1.15                              14.908571   \n",
      "...                            ...                                    ...   \n",
      "1169                        109.83                              18.855714   \n",
      "849                          70.61                              18.507143   \n",
      "602                           9.43                              15.414286   \n",
      "676                          26.56                              16.832857   \n",
      "97                           23.22                              14.944286   \n",
      "\n",
      "      reanalysis_tdtr_k  station_avg_temp_c  station_diur_temp_rng_c  \\\n",
      "818            2.428571           24.714286                 6.357143   \n",
      "172            2.228571           29.414286                 6.428571   \n",
      "401            1.885714           24.885714                 5.857143   \n",
      "924            2.071429           24.214286                 5.157143   \n",
      "1450          11.242857           25.633333                 9.200000   \n",
      "...                 ...                 ...                      ...   \n",
      "1169           8.228571           27.800000                 8.500000   \n",
      "849            2.757143           27.985714                 6.771429   \n",
      "602            3.385714           26.342857                 5.457143   \n",
      "676            3.085714           26.928571                 6.500000   \n",
      "97             2.514286           25.785714                 7.757143   \n",
      "\n",
      "      station_max_temp_c  station_min_temp_c  station_precip_mm  \n",
      "818                 30.6                20.6              101.1  \n",
      "172                 33.9                24.4               12.7  \n",
      "401                 29.4                20.6              152.4  \n",
      "924                 27.2                21.1               35.9  \n",
      "1450                34.0                20.0                2.5  \n",
      "...                  ...                 ...                ...  \n",
      "1169                33.3                22.6              100.8  \n",
      "849                 32.2                23.9               30.7  \n",
      "602                 29.4                22.8                4.4  \n",
      "676                 32.2                23.3               75.2  \n",
      "97                  31.7                21.7                5.9  \n",
      "\n",
      "[1456 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "df = dlt.merge(dft)\n",
    "df = df.sample(frac=1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"week_start_date\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"total_cases\"]\n",
    "X = df.drop(\"total_cases\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, columns = [\"city\", \"year\", \"weekofyear\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle = True, random_state = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hparam_tuning(model, X_val, y_val, param_grid):\n",
    "    return GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_absolute_error').fit(X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "from sklearn.feature_selection import f_regression\n",
    "pvalues = f_regression(X,y)\n",
    "array = list(pvalues[1])\n",
    "\n",
    "X = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>38</th>\n",
       "      <th>41</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.573180</td>\n",
       "      <td>-2.056904</td>\n",
       "      <td>-1.395704</td>\n",
       "      <td>-1.215695</td>\n",
       "      <td>-0.221345</td>\n",
       "      <td>-0.554526</td>\n",
       "      <td>-0.544808</td>\n",
       "      <td>-0.784242</td>\n",
       "      <td>0.383793</td>\n",
       "      <td>-0.482958</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.27735</td>\n",
       "      <td>-0.27735</td>\n",
       "      <td>-0.27735</td>\n",
       "      <td>3.605551</td>\n",
       "      <td>-0.19245</td>\n",
       "      <td>-0.140028</td>\n",
       "      <td>-0.140028</td>\n",
       "      <td>-0.140028</td>\n",
       "      <td>-0.140028</td>\n",
       "      <td>-0.140028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.347092</td>\n",
       "      <td>-0.686668</td>\n",
       "      <td>-0.091598</td>\n",
       "      <td>-0.468777</td>\n",
       "      <td>0.713309</td>\n",
       "      <td>0.434269</td>\n",
       "      <td>0.832114</td>\n",
       "      <td>-0.349778</td>\n",
       "      <td>0.814211</td>\n",
       "      <td>0.128214</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.27735</td>\n",
       "      <td>-0.27735</td>\n",
       "      <td>-0.27735</td>\n",
       "      <td>-0.277350</td>\n",
       "      <td>-0.19245</td>\n",
       "      <td>-0.140028</td>\n",
       "      <td>-0.140028</td>\n",
       "      <td>-0.140028</td>\n",
       "      <td>-0.140028</td>\n",
       "      <td>-0.140028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.211505</td>\n",
       "      <td>-1.178130</td>\n",
       "      <td>0.012707</td>\n",
       "      <td>-0.044861</td>\n",
       "      <td>-0.802346</td>\n",
       "      <td>-1.225089</td>\n",
       "      <td>-0.258536</td>\n",
       "      <td>-1.001474</td>\n",
       "      <td>0.266407</td>\n",
       "      <td>0.355323</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.27735</td>\n",
       "      <td>-0.27735</td>\n",
       "      <td>-0.27735</td>\n",
       "      <td>-0.277350</td>\n",
       "      <td>-0.19245</td>\n",
       "      <td>-0.140028</td>\n",
       "      <td>-0.140028</td>\n",
       "      <td>-0.140028</td>\n",
       "      <td>-0.140028</td>\n",
       "      <td>-0.140028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.942107</td>\n",
       "      <td>-1.135471</td>\n",
       "      <td>0.396589</td>\n",
       "      <td>0.827344</td>\n",
       "      <td>-1.079164</td>\n",
       "      <td>-1.549005</td>\n",
       "      <td>-2.437021</td>\n",
       "      <td>-1.280773</td>\n",
       "      <td>-0.124882</td>\n",
       "      <td>-1.616303</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.27735</td>\n",
       "      <td>-0.27735</td>\n",
       "      <td>-0.27735</td>\n",
       "      <td>-0.277350</td>\n",
       "      <td>-0.19245</td>\n",
       "      <td>-0.140028</td>\n",
       "      <td>-0.140028</td>\n",
       "      <td>-0.140028</td>\n",
       "      <td>-0.140028</td>\n",
       "      <td>-0.140028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.923502</td>\n",
       "      <td>1.205040</td>\n",
       "      <td>0.743622</td>\n",
       "      <td>0.506918</td>\n",
       "      <td>-0.776033</td>\n",
       "      <td>-0.412458</td>\n",
       "      <td>-1.326660</td>\n",
       "      <td>1.636345</td>\n",
       "      <td>-2.198715</td>\n",
       "      <td>-0.443871</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.27735</td>\n",
       "      <td>-0.27735</td>\n",
       "      <td>-0.27735</td>\n",
       "      <td>-0.277350</td>\n",
       "      <td>-0.19245</td>\n",
       "      <td>-0.140028</td>\n",
       "      <td>-0.140028</td>\n",
       "      <td>-0.140028</td>\n",
       "      <td>-0.140028</td>\n",
       "      <td>-0.140028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         5         6         7   \\\n",
       "0 -2.573180 -2.056904 -1.395704 -1.215695 -0.221345 -0.554526 -0.544808   \n",
       "1 -0.347092 -0.686668 -0.091598 -0.468777  0.713309  0.434269  0.832114   \n",
       "2 -1.211505 -1.178130  0.012707 -0.044861 -0.802346 -1.225089 -0.258536   \n",
       "3 -1.942107 -1.135471  0.396589  0.827344 -1.079164 -1.549005 -2.437021   \n",
       "4  0.923502  1.205040  0.743622  0.506918 -0.776033 -0.412458 -1.326660   \n",
       "\n",
       "         8         9         11  ...       34       35       36        38  \\\n",
       "0 -0.784242  0.383793 -0.482958  ... -0.27735 -0.27735 -0.27735  3.605551   \n",
       "1 -0.349778  0.814211  0.128214  ... -0.27735 -0.27735 -0.27735 -0.277350   \n",
       "2 -1.001474  0.266407  0.355323  ... -0.27735 -0.27735 -0.27735 -0.277350   \n",
       "3 -1.280773 -0.124882 -1.616303  ... -0.27735 -0.27735 -0.27735 -0.277350   \n",
       "4  1.636345 -2.198715 -0.443871  ... -0.27735 -0.27735 -0.27735 -0.277350   \n",
       "\n",
       "        41        82        83        84        86        87  \n",
       "0 -0.19245 -0.140028 -0.140028 -0.140028 -0.140028 -0.140028  \n",
       "1 -0.19245 -0.140028 -0.140028 -0.140028 -0.140028 -0.140028  \n",
       "2 -0.19245 -0.140028 -0.140028 -0.140028 -0.140028 -0.140028  \n",
       "3 -0.19245 -0.140028 -0.140028 -0.140028 -0.140028 -0.140028  \n",
       "4 -0.19245 -0.140028 -0.140028 -0.140028 -0.140028 -0.140028  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def removeHighPValueFeature(array,X,threshold):\n",
    "    col = 0\n",
    "    for v in array:\n",
    "        if v > threshold:\n",
    "            col = int(array.index(v,col))\n",
    "            X = X.drop(col, axis=1)\n",
    "    return X\n",
    "\n",
    "X = removeHighPValueFeature(array,X,0.01)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_tt, X_val, y_tt, y_val = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model, X, y):\n",
    "    errors = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred = [abs(elem) for elem in y_pred]\n",
    "        MAE = mean_absolute_error(y_test, y_pred)\n",
    "        errors.append(MAE)\n",
    "\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression\n",
      "18.27\n",
      "\n",
      "Lasso\n",
      "17.96\n",
      "\n",
      "Ridge\n",
      "18.22\n",
      "\n",
      "KNeighborsRegressor\n",
      "15.11\n",
      "\n",
      "DecisionTreeRegressor\n",
      "19.45\n",
      "\n",
      "SVR\n",
      "16.86\n",
      "\n",
      "GradientBoostingRegressor\n",
      "14.79\n",
      "\n",
      "RandomForestRegressor\n",
      "15.09\n",
      "\n",
      "BaggingRegressor\n",
      "15.70\n",
      "\n",
      "AdaBoostRegressor\n",
      "36.28\n",
      "\n",
      "MLPRegressor\n",
      "15.81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [LinearRegression(), Lasso(), Ridge(), KNeighborsRegressor(), DecisionTreeRegressor(), SVR(), \n",
    "          GradientBoostingRegressor(), RandomForestRegressor(), BaggingRegressor(),\n",
    "          AdaBoostRegressor(), MLPRegressor()]#, MultinomialNB()]\n",
    "              \n",
    "for model in models:\n",
    "    errors = run(model, X_tt ,y_tt)\n",
    "    print(type(model).__name__)\n",
    "    print(\"%.2f\\n\" %np.mean(errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Lasso(), {'alpha': [1, 3, 10]}], [Ridge(), {'alpha': [1, 3, 10]}], [DecisionTreeRegressor(), {'max_depth': [2, 4, 8, 16, 32, None], 'max_features': ['auto', 'sqrt'], 'min_samples_split': [2, 5, 10]}], [KNeighborsRegressor(), {'n_neighbors': [1, 3, 10, 30, 100]}], [SVR(), {'C': [1, 3, 10, 30], 'epsilon': [0.1, 0.3, 1.0]}], [MLPRegressor(), {'hidden_layer_sizes': [(100, 10), (100, 30), (100, 100), (100, 200)], 'activation': ['relu', 'logistic', 'tanh'], 'solver': ['sgd', 'adam']}]]\n"
     ]
    }
   ],
   "source": [
    "grid_lasso = {'alpha': [1, 3, 10]}\n",
    "grid_ridge = {'alpha': [1, 3, 10]}\n",
    "grid_dtr = {'max_depth': [2, 4, 8, 16, 32, None], 'max_features': ['auto', 'sqrt'], 'min_samples_split': [2, 5, 10]}\n",
    "grid_knnr = {'n_neighbors' : [1, 3, 10 , 30, 100]}\n",
    "grid_svr = {'C' : [1, 3 , 10, 30], 'epsilon': [0.1, 0.3, 1.0]}\n",
    "grid_mlpr = {'hidden_layer_sizes': [(100, 10),(100, 30),(100,100), (100,200)], 'activation': ['relu', 'logistic', 'tanh'], 'solver': ['sgd', 'adam']}\n",
    "\n",
    "model = [Lasso(), Ridge(), DecisionTreeRegressor(), KNeighborsRegressor(), SVR(), MLPRegressor()]\n",
    "grid = [grid_lasso, grid_ridge, grid_dtr, grid_knnr, grid_svr, grid_mlpr]\n",
    "\n",
    "pairs = [[a,b] for (a,b) in list(zip(model,grid))]\n",
    "print(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Lasso: \n",
      "{'alpha': 3}\n",
      "18.67\n",
      "\n",
      "Model Ridge: \n",
      "{'alpha': 10}\n",
      "18.22\n",
      "\n",
      "Model DecisionTreeRegressor: \n",
      "{'max_depth': 4, 'max_features': 'sqrt', 'min_samples_split': 2}\n",
      "19.76\n",
      "\n",
      "Model KNeighborsRegressor: \n",
      "{'n_neighbors': 10}\n",
      "16.08\n",
      "\n",
      "Model SVR: \n",
      "{'C': 30, 'epsilon': 1.0}\n",
      "14.84\n",
      "\n",
      "Model MLPRegressor: \n",
      "{'activation': 'relu', 'hidden_layer_sizes': (100, 30), 'solver': 'sgd'}\n",
      "15.46\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.chdir(r'C:\\Users\\Mustafa Kaan\\Desktop\\Results3')\n",
    "for pair in pairs:\n",
    "    grid = hparam_tuning(pair[0], X_val, y_val, pair[1])\n",
    "    \n",
    "    print(\"Model %s: \" % type(pair[0]).__name__ )\n",
    "    print(grid.best_params_)\n",
    "    errors = run(pair[0].set_params(**grid.best_params_), X_tt, y_tt)\n",
    "    print(\"%.2f\\n\" %np.mean(errors))\n",
    "    \n",
    "    params = pair[1].keys()\n",
    "    params = ['param_' + str(param) for param in params]\n",
    "    params.append('mean_test_score')\n",
    "    grid_mean_scores = pd.DataFrame(grid.cv_results_)[params]\n",
    "    grid_mean_scores.to_excel(type(pair[0]).__name__ + \".xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_gbr = {'n_estimators': [5, 10, 50, 100, 120]}\n",
    "grid_rfr = {'n_estimators': [5, 10, 50, 100, 120]}\n",
    "grid_bgr = {'n_estimators': [5, 10, 50, 100, 120]}\n",
    "grid_abr = {'n_estimators': [5, 10, 50, 100, 120]}\n",
    "\n",
    "model = [GradientBoostingRegressor(), RandomForestRegressor(), BaggingRegressor(),\n",
    "          AdaBoostRegressor()]\n",
    "grid= [grid_gbr, grid_rfr, grid_bgr, grid_abr]\n",
    "pairs = [[a,b] for (a,b) in list(zip(model,grid))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model GradientBoostingRegressor: \n",
      "{'n_estimators': 50}\n",
      "15.34\n",
      "\n",
      "Model RandomForestRegressor: \n",
      "{'n_estimators': 50}\n",
      "15.10\n",
      "\n",
      "Model BaggingRegressor: \n",
      "{'n_estimators': 50}\n",
      "14.97\n",
      "\n",
      "Model AdaBoostRegressor: \n",
      "{'n_estimators': 10}\n",
      "21.35\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.chdir(r'C:\\Users\\Mustafa Kaan\\Desktop\\Results3')\n",
    "for pair in pairs:\n",
    "    grid = hparam_tuning(pair[0], X_val, y_val, pair[1])\n",
    "    \n",
    "    print(\"Model %s: \" % type(pair[0]).__name__ )\n",
    "    print(grid.best_params_)\n",
    "    errors = run(pair[0].set_params(**grid.best_params_), X_tt, y_tt)\n",
    "    print(\"%.2f\\n\" %np.mean(errors))\n",
    "    \n",
    "    params = pair[1].keys()\n",
    "    params = ['param_' + str(param) for param in params]\n",
    "    params.append('mean_test_score')\n",
    "    grid_mean_scores = pd.DataFrame(grid.cv_results_)[params]\n",
    "    grid_mean_scores.to_excel(type(pair[0]).__name__ + \".xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg1 = SVR().set_params(**{'C': 30, 'epsilon': 1.0})\n",
    "reg2 = MLPRegressor().set_params(**{'activation': 'relu', 'hidden_layer_sizes': (100, 30), 'solver': 'sgd'})\n",
    "reg3 = BaggingRegressor().set_params(**{'n_estimators': 50})\n",
    "estimators=[('svr', reg1), ('mlp', reg2), ('bgr', reg3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingRegressor\n",
      "12.77\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "vereg = VotingRegressor(estimators=estimators)\n",
    "errors = run(vereg, X ,y)\n",
    "print(type(vereg).__name__)\n",
    "print(\"%.2f\\n\" %np.mean(errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StackingRegressor\n",
      "12.57\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "sereg = StackingRegressor(\n",
    "        estimators=estimators,\n",
    "        final_estimator=LinearRegression())\n",
    "errors = run(sereg, X ,y)\n",
    "print(type(sereg).__name__)\n",
    "print(\"%.2f\\n\" %np.mean(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
